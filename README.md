# ğŸ¥ LLM Performance Comparison in a Healthcare App

## ğŸ“Œ Project Overview
This project compares the performance of various **Large Language Models (LLMs)** integrated into a healthcare-focused app. It applies **software engineering principles** to evaluate LLMs across multiple metrics and platforms.

---

## ğŸ¯ Application Use Case
The app allows users to input **healthcare-related questions**, which are processed by both **cloud-based** and **local LLMs**, enabling a detailed **performance comparison**.

---

## ğŸš€ Objectives

### 1ï¸âƒ£ Develop the App
- Build an interactive, secure app for healthcare-related chat with LLMs.
- Include **cloud-based APIs** (e.g., OpenAI, Gemini, Claude, Grok) and **local models**.

### 2ï¸âƒ£ Integrate Multiple LLMs
- Compare models from:
  - **Cloud-based**: OpenAI (ChatGPT), Gemini, Claude, Grok.
  - **Local**: bioGPT, LLama-3.2 (1B).

### 3ï¸âƒ£ Test Across Devices & Conditions
- Evaluate performance on **mobile**, **laptop**, **cloud VMs**, and **edge devices**.
- Simulate **varied network conditions** to test reliability and latency.

### 4ï¸âƒ£ Measure Key Metrics
- â± **Response Time**  
- ğŸ¯ **Accuracy & Relevance**
- ğŸ§  **Resource Usage** (CPU, RAM, GPU)
- ğŸš§ **Latency & Delay Analysis**

### 5ï¸âƒ£ Visualize Data
- Collect and analyze results using **charts, graphs, and tables**.

---

## ğŸ› ï¸ Technologies Used

### ğŸ”¹ Primary Language
- **TypeScript**

### ğŸ”¹ IDE
- **Visual Studio Code (VSCode)**

### ğŸ”¹ Frontend
- **React Native** â€“ UI development  
- **Zustand** â€“ State management  
- **Ky** â€“ HTTP requests  
- **Gluestick** â€“ UI component library  
- **Firebase Auth** â€“ Authentication  

### ğŸ”¹ Backend
- **Express.js** â€“ API and service handling  
- **Mongoose (ORM)** â€“ MongoDB interaction  
- **Axios** â€“ Internal and external HTTP requests

### ğŸ”¹ Database
- **MongoDB**

### ğŸ”¹ Microservices
- **Express.js** â€“ Microservice framework  
- **LLM SDKs/APIs** â€“ Official packages from OpenAI, Anthropic, Google, etc.

---

## ğŸ“² How to Use the App

1. **Sign in** with your credentials via Firebase.
2. Fill in patient details (Name, Age, Height, Weight, Symptoms).
3. Tap **Start Chatting**.
4. Choose your preferred LLM from the dropdown.
5. Begin the conversation and **compare results** across models.

> ğŸ” If a signed-out user tries to access any protected page (like the form or chat), the app **redirects them to the Sign-In screen**.

---

## ğŸ§‘â€ğŸ’» User Features

- ğŸ§¾ Fetch & **resume previous chat sessions**.
- ğŸ§  Compare different model responses on identical queries.
- ğŸ“ˆ View **performance stats** and **model efficiency** insights.

---

## ğŸ“Š Expected Outcomes

- In-depth analysis of **cloud vs. local LLMs** in a real-world app.
- Software engineering insights into **LLM integration**.
- Visualization dashboards to present the performance metrics.

---

## ğŸ§± Architecture Diagrams

> âœ… Updated versions of the following diagrams are required:
- Class Diagrams (Class & Class2)
- Activity Diagram
- State Diagram
- Network Architecture Diagram
- Sequence Diagram (with correct tools and tech stack)

### ğŸ” Auth Flow (Activity/State Diagram)
1. User opens the app â†’ lands on homepage.
2. Clicks button to go to form.
3. If **not signed in** â†’ auto redirected to **Sign-In** page.

---

### ğŸ”® Future Enhancements
-  Expand into other industries like education, finance, legal.

-  Add support for new LLMs as they are released.

-  Enhance the benchmarking engine for deeper analysis and automation.

### ğŸ“š License
This project is licensed under the MIT License.

### ğŸ‘¥ Contributors
-  Adheil Gupta (23BDS002)
-  Arnav Gupta (23BDS009)
-  Atharva Agrawal (23BDS010)
-  SuryaNarayan Rao (23BDS025)

# ğŸš€ Project Setup

Follow these steps to set up and run the project locally:

---

## ğŸ–¥ï¸ Clone the Repository

```bash
git clone <repo-url>
cd <repo-directory>
```

---

## ğŸŒ Start Frontend

```bash
cd frontend
```

1. Replace `<your-IP>` in the project files with the **IP address of the backend server**.
2. Open the `firebaseConfig.js` file and populate it with your **Firebase project configuration**.

### ğŸ“¦ Install Dependencies

```bash
npx install-expo-modules@latest
npm install
```

### â–¶ï¸ Start the Development Server

```bash
npx expo start
```

---

## ğŸ§  Start Microservice (Models)

```bash
cd models
```

1. Create a `.env` file.
2. Follow the format provided in `.env.example`.
3. Populate the keys using your **model files and credentials**.

### ğŸ“¦ Install Dependencies

```bash
npm install
```

### â–¶ï¸ Start the Development Server

```bash
npm start
```

---

## ğŸ› ï¸ Start Backend

```bash
cd backend
```

1. Create a `.env` file.
2. Follow the format provided in `.env.example`.
3. Populate the keys using your **own configuration values**.

### ğŸ“¦ Install Dependencies

```bash
npm install
```

### â–¶ï¸ Start the Development Server

```bash
npm start
```




